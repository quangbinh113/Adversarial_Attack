{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset\n",
        "The dataset available in the following links \\\\\n",
        "The base dataset (Non-noise): https://drive.google.com/file/d/1OH5vczwBYIxXXpX2VaYWmLXRUvJBBxQN/view?usp=sharing \\\\\n",
        "The noise-adding dataset: https://drive.google.com/file/d/1QSA5HmpNdtrJzeGUFfv6MQVWR0AaHAz9/view?usp=sharing \\\\\n",
        "\n",
        "Note that the labels are transformed into YOLOv5 format and divide into training and test sets so that it is not necessary to perform preprocessing."
      ],
      "metadata": {
        "id": "nIxoYjO2aCBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the dataset\n",
        "#Run only this cell\n",
        "\n",
        "!unzip noise_dataset.zip -d /content\n",
        "!unzip /content/drive/MyDrive/Yolo_1.zip -d /content"
      ],
      "metadata": {
        "id": "RmTJycUiav-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The following cells contain code to perform transformation and preprocessing images"
      ],
      "metadata": {
        "id": "IaHWYdkJcMnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob as g\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from shutil import copy, move\n",
        "from google.colab.files import download\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8ZqkMwmBcQ9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_img_train = '/content/newDataset/images/train'\n",
        "new_img_val = '/content/newDataset/images/val'\n",
        "new_lbl_train = '/content/newDataset/label/train'\n",
        "new_lbl_val = '/content/newDataset/label/val'\n",
        "\n",
        "os.makedirs(new_img_train, exist_ok=True)\n",
        "os.makedirs(new_img_val, exist_ok=True)\n",
        "os.makedirs(new_lbl_train, exist_ok=True)\n",
        "os.makedirs(new_lbl_val, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "08iZAtS6cTrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show an image with its bounding box\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "#Show an image with bounding box\n",
        "path = '/content/images'\n",
        "df = pd.read_csv('/content/faces.csv')\n",
        "image_path = str(df['image_name'].iloc[0])\n",
        "x0 = int(df['x0'].iloc[0])\n",
        "y0 = int(df['y0'].iloc[0])\n",
        "x1 = int(df['x1'].iloc[0])\n",
        "y1 = int(df['y1'].iloc[0])\n",
        "image = Image.open(os.path.join(path,image_path))\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "draw.rectangle([(x0,y0), (x1,y1)], outline='red', width=2)\n",
        "image.show()"
      ],
      "metadata": {
        "id": "mR-Ld-9dcXqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert from csvfile to label and divide images to train/test folders\n",
        "\n",
        "df = pd.read_csv('/content/faces.csv')\n",
        "nums = len(df)\n",
        "train_img_path = '/content/newDataset/images/train'\n",
        "val_img_path = '/content/newDataset/images/val'\n",
        "train_lbl_path = '/content/newDataset/label/train'\n",
        "val_lbl_path = '/content/newDataset/label/val'\n",
        "split_ratio = 0.85\n",
        "for index in tqdm(range(len(df))):\n",
        "  image_path = str(df['image_name'].iloc[index])\n",
        "  width = int(df['width'].iloc[index])\n",
        "  height = int(df['height'].iloc[index])\n",
        "  x0 = int(df['x0'].iloc[index])\n",
        "  y0 = int(df['y0'].iloc[index])\n",
        "  x1 = int(df['x1'].iloc[index])\n",
        "  y1 = int(df['y1'].iloc[index])\n",
        "  #normalized\n",
        "  normalized_x0 = x0 / width\n",
        "  normalized_y0 = y0 / height\n",
        "  normalized_x1 = x1 / width\n",
        "  normalized_y1 = y1 / height\n",
        "\n",
        "  #convertToYolo\n",
        "  x_center = (normalized_x0 + normalized_x1) / 2\n",
        "  y_center = (normalized_y0 + normalized_y1) / 2\n",
        "  bbox_width = normalized_x1 - normalized_x0\n",
        "  bbox_height = normalized_y1 - normalized_y0\n",
        "\n",
        "  if index < nums * split_ratio:\n",
        "    label_path = os.path.join(train_lbl_path, image_path.split('.')[0] + '.txt')\n",
        "    f = open(label_path, 'w')\n",
        "    yolo_line = f'{0} {x_center} {y_center} {bbox_width} {bbox_height}'\n",
        "    f.write(yolo_line)\n",
        "    f.close()\n",
        "    copy(os.path.join('/content/images', image_path), train_img_path)\n",
        "  else:\n",
        "    label_path = os.path.join(val_lbl_path, image_path.split('.')[0]+ '.txt')\n",
        "    f = open(label_path, 'w')\n",
        "    yolo_line = f'{0} {x_center} {y_center} {bbox_width} {bbox_height}'\n",
        "    f.write(yolo_line)\n",
        "    f.close()\n",
        "    copy(os.path.join('/content/images', image_path), val_img_path)"
      ],
      "metadata": {
        "id": "e-TrOBQGcgxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/newDataset/images/train')))\n",
        "print(len(os.listdir('/content/newDataset/images/val')))"
      ],
      "metadata": {
        "id": "cCCsM6XCcqGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a grid of images\n",
        "names = g('/content/newDataset/label/*/*')\n",
        "print(names)\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "images = []\n",
        "for _ in range(25):\n",
        "    n = np.random.randint(0, len(names))\n",
        "    f = open(names[n])\n",
        "\n",
        "    lines = f.readlines()\n",
        "    classes = list(map(lambda x: int(x[0]), lines))\n",
        "    lines = list(map(lambda x:x.rstrip()[2:], lines))\n",
        "    objects = list(map(lambda x:(x.split()), lines))\n",
        "\n",
        "    img = cv2.imread(names[n].replace('txt','jpg').replace('label', 'images'))\n",
        "    print(type(img))\n",
        "    for c, bbox in zip(classes, objects):\n",
        "        bbox = list(map(lambda x:float(x), bbox))\n",
        "        x,y,w,h = bbox\n",
        "        img_h = img.shape[0]\n",
        "        img_w = img.shape[1]\n",
        "        x = int(x * img_w)\n",
        "        w = int(w * img_w)\n",
        "        y = int(y * img_h)\n",
        "        h = int(h * img_h)\n",
        "        color = (255,100,50)\n",
        "        cv2.rectangle(img , (int(x-w/2), int(y-h/2)), (int(x+w/2), int(y+h/2)), color , 6)\n",
        "    # plt.figure(figsize = (8,8))\n",
        "    # plt.imshow(img[:,:,::-1]); plt.axis('off')\n",
        "    # print(f'number of bounding boxes : {len(classes)}')\n",
        "    images.append(img[:,:,::-1])\n",
        "fig = plt.figure(figsize=(16., 16.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(5 ,5),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, images):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T4n9QEqscsIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_address = '/content/newDataset/labels/train/'\n",
        "imgs_address = '/content/newDataset/images/train/'\n",
        "np.random.seed(101)\n",
        "names = os.listdir(imgs_address)\n",
        "randvec = np.random.rand(len(names))\n",
        "i = 0\n",
        "for name in tqdm(names[:]):\n",
        "  i += 1\n",
        "  copy(imgs_address + name,  '/content/Yolo_1/images/train/' + name)\n",
        "  copy(labels_address + name.split('.')[0] + '.txt' , '/content/Yolo_1/labels/train/' + name.split('.')[0] + '.txt')"
      ],
      "metadata": {
        "id": "hnIXfDbOc4IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Model"
      ],
      "metadata": {
        "id": "ufI_1FbvdDay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "torch.cuda.get_device_name()"
      ],
      "metadata": {
        "id": "APXnje1EdHdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clone the model and write custom dataset\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -qr /content/yolov5/requirements.txt\n",
        "%cd yolov5\n",
        "clear_output()\n",
        "f = open('/content/yolov5/data/dataset.yaml', 'w')\n",
        "f.write('train: /content/content/noise_dataset/images/train')\n",
        "f.write('\\nval: /content/content/noise_dataset/images/val')\n",
        "f.write('\\nnc: {}'.format(1))\n",
        "f.write(\"\\nnames: ['Face']\")\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "97Sv3ybrdN5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model from scratch\n",
        "!python train.py --multi-scale --batch 32 --data /content/yolov5/data/dataset.yaml --cfg /content/yolov5/models/yolov5s.yaml --epochs num_epoch --weights path/to/weights\n"
      ],
      "metadata": {
        "id": "2BHl8XNGdWCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run test\n",
        "!python val.py --batch 32 --data /content/yolov5/data/dataset.yaml --weights path/to/weights"
      ],
      "metadata": {
        "id": "9ig3t4WgdiLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference mode\n",
        "!python detect.py --source path/to/source --weights path/to/weights\n"
      ],
      "metadata": {
        "id": "qfxZ78RKdpP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find the weights here: \\\\\n",
        "For non-noise dataset weight: https://drive.google.com/file/d/1b10veNEl4LDnjsaODdsa90D2r4ztoT9h/view?usp=sharing \\\\\n",
        "For noise dataset weight: https://drive.google.com/file/d/1FgVozWlrhPHoPQ47pW4cUXEBnezU7QzL/view?usp=sharing \\\\\n",
        "or just train from scrach"
      ],
      "metadata": {
        "id": "YbIbJZopd0eS"
      }
    }
  ]
}